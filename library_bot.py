import requests
from bs4 import BeautifulSoup
import os
import time
import json
import re
import urllib3
import traceback 
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ==========================================
# [ì„¤ì • ì˜ì—­]
# ==========================================
DISCORD_WEBHOOK_URL = os.environ.get("library_WEBHOOK_URL")
# ê´€ë¦¬ì ì—ëŸ¬ ì•Œë¦¼ìš© ì›¹í›„í¬
MONITOR_WEBHOOK_URL = os.environ.get("MONITOR_WEBHOOK_URL")

# [í…ŒìŠ¤íŠ¸ìš©] ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œ ì£¼ì„ í•´ì œ
# DISCORD_WEBHOOK_URL = "https://discord.com/api/webhooks/..."
# MONITOR_WEBHOOK_URL = "https://discord.com/api/webhooks/..."
URL = "https://library.cnu.ac.kr/bbs/list/1"
DATA_FILE = "library_data.json"

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}
# ==========================================

# ===[ì„¸ì…˜ ìƒì„±ê¸°]===
def get_session():
    """Retry ê°€ëŠ¥í•œ ì„¸ì…˜ ìƒì„±"""
    session = requests.Session()
    retry = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session

# ===[ID ì¶”ì¶œê¸°]===
def extract_id_from_link(link):
    """ë§í¬ì—ì„œ 1_...(ê³ ìœ ë²ˆí˜¸) ì¶”ì¶œ"""
    match_under = re.search(r'_(\d+)$', link)
    if match_under:
        return int(match_under.group(1))
    
    # ì˜ˆë¹„ìš© (ìŠ¬ë˜ì‹œ íŒ¨í„´)
    match_slash = re.search(r'/(\d+)$', link)
    if match_slash:
        return int(match_slash.group(1))
        
    return 0

# ===[ë””ì½” ì „ì†¡ê¸°]===
def send_discord_message(new_notices):
    """í•™ìƒìš© ê³µì§€ ì•Œë¦¼ ì „ì†¡"""
    if not new_notices: return

    if not DISCORD_WEBHOOK_URL:
        print("âš  ì›¹í›„í¬ URLì´ ì—†ìŒ")
        return

    count = len(new_notices)
    message_content = f"### ğŸ“š [ì¼ë°˜ê³µì§€] ìƒˆ ê¸€ {count}ê±´\n\n"
    
    for notice in new_notices:
        title = notice['title']
        link = notice['link']
        icon = "â–¶" if notice['is_top'] else "â–·"
        message_content += f"{icon} [{title}](<{link}>)\n"

    try:
        requests.post(DISCORD_WEBHOOK_URL, json={"content": message_content})
        print(f"âœ‰ [ì „ì†¡ ì™„ë£Œ] ë„ì„œê´€ ê³µì§€ {count}ê±´")
    except Exception as e:
        print(f"âš  [ì „ì†¡ ì‹¤íŒ¨] {e}")

# ê´€ë¦¬ì ì‹¬í”Œ ì•Œë¦¼ í•¨ìˆ˜
def send_simple_error_log():
    if not MONITOR_WEBHOOK_URL: return 

    now = time.strftime('%Y-%m-%d %H:%M:%S')
    
    # ì‹¬í”Œí•œ ë©”ì‹œì§€ ë‚´ìš©
    content = f"ğŸš¨ **[ë„ì„œê´€ ë´‡ ì˜¤ë¥˜ ë°œìƒ]** \n ì‹œê°„: {now}"
    
    try:
        requests.post(MONITOR_WEBHOOK_URL, json={"content": content})
        print("âœ‰ [ê´€ë¦¬ì ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ]")
    except:
        print("âš  ê´€ë¦¬ì ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")

# ===[MAIN]===
def check_library_notices():
    print("\n" + "â”" * 40)
    print(f"ğŸ¤– ë„ì„œê´€ ê³µì§€ë´‡ ì‹¤í–‰: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # 1. ê¸°ì¡´ ë°ì´í„° íŒŒì¼ ì½ê¸°
        saved_data = {}
        if os.path.exists(DATA_FILE):
            with open(DATA_FILE, "r", encoding="utf-8") as f:
                try: saved_data = json.load(f)
                except: saved_data = {}
        
        last_id = saved_data.get("last_id", 0)

        # 2. ì›¹í˜ì´ì§€ ì ‘ì†
        session = get_session()
        response = session.get(URL, headers=HEADERS, verify=False, timeout=10)
        response.encoding = 'utf-8'

        # 3. HTML íŒŒì‹±
        soup = BeautifulSoup(response.text, 'html.parser')

        # 4. ê²Œì‹œê¸€ ì¤„(Row) íƒìƒ‰
        rows = soup.select('tbody > tr')
        if not rows:
            # ê²Œì‹œê¸€ì„ ëª» ì°¾ì€ ê²ƒë„ ì—ëŸ¬ ìƒí™©ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì˜ˆì™¸ ë°œìƒì‹œí‚´            print("âš  ê²Œì‹œë¬¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return

        new_notices = []
        max_id_in_this_scan = last_id

        # 5. ê° ì¤„ ë°˜ë³µ ê²€ì‚¬
        for row in rows:
            a_tag = row.select_one('td.title a') or row.select_one('td.subject a') or row.select_one('a')
            if not a_tag: continue

            title = a_tag.get('title') or a_tag.text.strip()
            title = title.replace("ìƒˆê¸€", "").strip()
            
            href = a_tag.get('href')
            link = f"https://library.cnu.ac.kr{href}"
            
            article_id = extract_id_from_link(link)
            if article_id == 0: continue

            is_top = 'always' in row.get('class', [])

            if article_id > last_id:
                new_notices.append({
                    "id": article_id,
                    "title": title,
                    "link": link,
                    "is_top": is_top
                })
                if article_id > max_id_in_this_scan:
                    max_id_in_this_scan = article_id

        # 6. ìµœì´ˆ ì‹¤í–‰ ì²˜ë¦¬
        if last_id == 0 and max_id_in_this_scan > 0:
            print(f"â˜ [ë„ì„œê´€] ìµœì´ˆ ì‹¤í–‰ - ê¸°ì¤€ì (ID: {max_id_in_this_scan})ë§Œ ì„¤ì •")
            with open(DATA_FILE, "w", encoding="utf-8") as f:
                json.dump({"last_id": max_id_in_this_scan}, f, indent=4)
            return

        # 7. ìƒˆ ê¸€ ì „ì†¡ ë° ì €ì¥
        if new_notices:
            new_notices.sort(key=lambda x: x['id'])
            send_discord_message(new_notices)
            
            with open(DATA_FILE, "w", encoding="utf-8") as f:
                json.dump({"last_id": max_id_in_this_scan}, f, indent=4)
            print("â˜‘ ë„ì„œê´€ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        else:
            print("â˜’ ë„ì„œê´€ ìƒˆ ì†Œì‹ ì—†ìŒ")

    # ì—ëŸ¬ ë°œìƒ ì‹œ ì²˜ë¦¬
    except Exception as e:
        print(f"âš  ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # 1. ê¹ƒí—ˆë¸Œ ë¡œê·¸ìš© ìƒì„¸ ì—ëŸ¬ ì¶œë ¥
        traceback.print_exc()
        
        # 2. ê´€ë¦¬ìì—ê²Œ ì‹¬í”Œ ì•Œë¦¼ ì „ì†¡
        send_simple_error_log()

if __name__ == "__main__":
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    check_library_notices()
